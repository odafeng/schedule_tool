"""
MLè¨“ç·´è³‡æ–™åˆ†æé é¢
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import numpy as np

from backend.analyzers import GradingSystem

def render():
    """æ¸²æŸ“MLåˆ†æé é¢"""
    st.header("ğŸ¤– æ©Ÿå™¨å­¸ç¿’è¨“ç·´è³‡æ–™ç®¡ç†")
    
    if st.session_state.last_scheduler is None or st.session_state.last_scheduler.solution_pool is None:
        st.info("è«‹å…ˆåŸ·è¡Œæ’ç­ä¸¦å‹¾é¸ã€Œæ”¶é›†æ‰€æœ‰å€™é¸è§£ã€é¸é …")
        return
    
    solution_pool = st.session_state.last_scheduler.solution_pool
    pool_metrics = solution_pool.get_diversity_metrics()
    
    # è§£æ± æ¦‚è¦½
    render_pool_overview(pool_metrics)
    
    # ç­‰ç´šåˆ†å¸ƒ
    render_grade_distribution(pool_metrics, solution_pool)
    
    # ç‰¹å¾µåˆ†æ
    render_feature_analysis(solution_pool)
    
    # Topè§£å±•ç¤º
    render_top_solutions(solution_pool)
    
    # è¨“ç·´è³‡æ–™åŒ¯å‡º
    render_export_section(solution_pool)
    
    # è¨“ç·´å»ºè­°
    render_training_suggestions()

def render_pool_overview(pool_metrics):
    """æ¸²æŸ“è§£æ± æ¦‚è¦½"""
    st.subheader("ğŸ“Š è§£æ± æ¦‚è¦½")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç¸½è§£æ•¸é‡", pool_metrics.get('pool_size', 0))
    with col2:
        st.metric("å”¯ä¸€è§£æ•¸é‡", pool_metrics.get('unique_schedules', 0))
    with col3:
        st.metric("å¹³å‡åˆ†æ•¸", f"{pool_metrics.get('avg_score', 0):.1f}")
    with col4:
        st.metric("åˆ†æ•¸æ¨™æº–å·®", f"{pool_metrics.get('score_std', 0):.1f}")

def render_grade_distribution(pool_metrics, solution_pool):
    """æ¸²æŸ“ç­‰ç´šåˆ†å¸ƒ"""
    st.subheader("ğŸ“ˆ è§£çš„ç­‰ç´šåˆ†å¸ƒ")
    
    grade_dist = pool_metrics.get('grade_distribution', {})
    
    if grade_dist:
        # æº–å‚™ç­‰ç´šèªªæ˜
        grading_system = GradingSystem()
        grade_descriptions = {
            grade: grading_system.get_grade_description(grade)
            for grade in ['S', 'A', 'B', 'C', 'D', 'F']
        }
        
        # é¡¯ç¤ºç­‰ç´šåˆ†å¸ƒåœ–è¡¨
        grades = list(grade_dist.keys())
        counts = list(grade_dist.values())
        
        fig_grades = px.bar(
            x=grades,
            y=counts,
            title="è§£çš„ç­‰ç´šåˆ†å¸ƒ",
            labels={'x': 'ç­‰ç´š', 'y': 'æ•¸é‡'},
            color=grades,
            color_discrete_map={
                'S': '#FFD700',  # é‡‘è‰²
                'A': '#00FF00',  # ç¶ è‰²
                'B': '#87CEEB',  # å¤©è—è‰²
                'C': '#FFA500',  # æ©™è‰²
                'D': '#FF6347',  # ç•ªèŒ„ç´…
                'F': '#FF0000'   # ç´…è‰²
            }
        )
        st.plotly_chart(fig_grades, use_container_width=True)
        
        # ç­‰ç´šèªªæ˜
        with st.expander("ğŸ“– ç­‰ç´šèªªæ˜", expanded=False):
            for grade, desc in grade_descriptions.items():
                if grade in grade_dist:
                    st.write(f"**{grade}ç´š** ({grade_dist[grade]}å€‹): {desc}")

def render_feature_analysis(solution_pool):
    """æ¸²æŸ“ç‰¹å¾µåˆ†æ"""
    st.subheader("ğŸ”¬ ç‰¹å¾µåˆ†æ")
    
    # é¸æ“‡è¦åˆ†æçš„ç­‰ç´š
    available_grades = list(set(s.grade for s in solution_pool.solution_pool))
    
    if available_grades:
        selected_grades = st.multiselect(
            "é¸æ“‡è¦åˆ†æçš„ç­‰ç´š",
            available_grades,
            default=available_grades[:2] if len(available_grades) >= 2 else available_grades
        )
        
        if selected_grades:
            # æ”¶é›†é¸å®šç­‰ç´šçš„è§£
            selected_solutions = []
            for grade in selected_grades:
                selected_solutions.extend(solution_pool.get_solutions_by_grade(grade))
            
            if selected_solutions:
                # æå–ç‰¹å¾µ
                feature_data = []
                for sol in selected_solutions:
                    feature_dict = sol.features.to_dict()
                    feature_dict['grade'] = sol.grade
                    feature_dict['score'] = sol.score
                    feature_data.append(feature_dict)
                
                df_features = pd.DataFrame(feature_data)
                
                # é¡¯ç¤ºé—œéµç‰¹å¾µå°æ¯”
                col1, col2 = st.columns(2)
                
                with col1:
                    # å¡«å……ç‡å°æ¯”
                    fig_fill = px.box(
                        df_features,
                        x='grade',
                        y='fill_rate',
                        title='å¡«å……ç‡åˆ†å¸ƒ',
                        labels={'fill_rate': 'å¡«å……ç‡', 'grade': 'ç­‰ç´š'}
                    )
                    st.plotly_chart(fig_fill, use_container_width=True)
                
                with col2:
                    # é•è¦æ•¸å°æ¯”
                    fig_viol = px.box(
                        df_features,
                        x='grade',
                        y='hard_violations',
                        title='ç¡¬é•è¦æ•¸åˆ†å¸ƒ',
                        labels={'hard_violations': 'é•è¦æ•¸', 'grade': 'ç­‰ç´š'}
                    )
                    st.plotly_chart(fig_viol, use_container_width=True)
                
                # ç‰¹å¾µç›¸é—œæ€§ç†±åœ–
                with st.expander("ğŸ”¥ ç‰¹å¾µç›¸é—œæ€§ç†±åœ–", expanded=False):
                    # é¸æ“‡æ•¸å€¼ç‰¹å¾µ
                    numeric_features = [
                        'fill_rate', 'hard_violations', 'soft_violations',
                        'duty_variance', 'duty_std', 'gini_coefficient',
                        'preference_rate', 'weekend_coverage_rate',
                        'weekday_coverage_rate', 'avg_consecutive_days'
                    ]
                    
                    corr_matrix = df_features[numeric_features].corr()
                    
                    fig_corr = px.imshow(
                        corr_matrix,
                        labels=dict(color="ç›¸é—œä¿‚æ•¸"),
                        title="ç‰¹å¾µç›¸é—œæ€§çŸ©é™£",
                        color_continuous_scale='RdBu',
                        zmin=-1, zmax=1
                    )
                    st.plotly_chart(fig_corr, use_container_width=True)

def render_top_solutions(solution_pool):
    """æ¸²æŸ“æœ€ä½³è§£å±•ç¤º"""
    st.subheader("ğŸ† æœ€ä½³è§£å±•ç¤º")
    
    top_n = st.slider("é¡¯ç¤ºå‰Nå€‹æœ€ä½³è§£", 1, 20, 5)
    top_solutions = solution_pool.get_top_solutions(top_n)
    
    if top_solutions:
        solution_display = []
        for i, sol in enumerate(top_solutions, 1):
            solution_display.append({
                'æ’å': i,
                'è§£ID': sol.solution_id[:20] + "...",
                'åˆ†æ•¸': f"{sol.score:.1f}",
                'ç­‰ç´š': sol.grade,
                'å¡«å……ç‡': f"{sol.features.fill_rate*100:.1f}%",
                'ç¡¬é•è¦': sol.features.hard_violations,
                'è»Ÿé•è¦': sol.features.soft_violations,
                'åå¥½æ»¿è¶³': f"{sol.features.preference_rate*100:.1f}%",
                'ç”Ÿæˆæ–¹æ³•': sol.generation_method,
                'è¿­ä»£': sol.iteration
            })
        
        df_top = pd.DataFrame(solution_display)
        st.dataframe(df_top, use_container_width=True)

def render_export_section(solution_pool):
    """æ¸²æŸ“è¨“ç·´è³‡æ–™åŒ¯å‡º"""
    st.subheader("ğŸ’¾ è¨“ç·´è³‡æ–™åŒ¯å‡º")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # CSVæ ¼å¼åŒ¯å‡º
        if st.button("ğŸ“¥ åŒ¯å‡ºCSVè¨“ç·´è³‡æ–™", use_container_width=True):
            csv_data = solution_pool.export_training_data(format="csv")
            if csv_data:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label="ä¸‹è¼‰CSVæª”æ¡ˆ",
                    data=csv_data,
                    file_name=f"ml_training_data_{timestamp}.csv",
                    mime="text/csv"
                )
                st.success("CSVè¨“ç·´è³‡æ–™å·²æº–å‚™å¥½ä¸‹è¼‰ï¼")
    
    with col2:
        # JSONæ ¼å¼åŒ¯å‡º
        if st.button("ğŸ“¥ åŒ¯å‡ºJSONè¨“ç·´è³‡æ–™", use_container_width=True):
            json_data = solution_pool.export_training_data(format="json")
            if json_data:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label="ä¸‹è¼‰JSONæª”æ¡ˆ",
                    data=json_data,
                    file_name=f"ml_training_data_{timestamp}.json",
                    mime="application/json"
                )
                st.success("JSONè¨“ç·´è³‡æ–™å·²æº–å‚™å¥½ä¸‹è¼‰ï¼")
    
    with col3:
        # åŒ¯å‡ºçµ±è¨ˆå ±å‘Š
        if st.button("ğŸ“Š ç”Ÿæˆåˆ†æå ±å‘Š", use_container_width=True):
            report = generate_analysis_report(solution_pool)
            st.download_button(
                label="ä¸‹è¼‰åˆ†æå ±å‘Š",
                data=report,
                file_name=f"ml_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown"
            )
            st.success("åˆ†æå ±å‘Šå·²ç”Ÿæˆï¼")

def render_training_suggestions():
    """æ¸²æŸ“è¨“ç·´å»ºè­°"""
    st.subheader("ğŸ¯ æ©Ÿå™¨å­¸ç¿’è¨“ç·´å»ºè­°")
    
    with st.expander("ğŸ“š å¦‚ä½•ä½¿ç”¨é€™äº›è³‡æ–™è¨“ç·´AI", expanded=False):
        st.markdown("""
        ### 1. **ç›£ç£å¼å­¸ç¿’ï¼šæ’ç­å“è³ªé æ¸¬**
        ```python
        # ä½¿ç”¨éš¨æ©Ÿæ£®æ—é æ¸¬æ’ç­å“è³ª
        from sklearn.ensemble import RandomForestRegressor
        
        X = df[feature_columns]  # ç‰¹å¾µ
        y = df['score']          # ç›®æ¨™
        model = RandomForestRegressor()
        model.fit(X, y)
        ```
        
        ### 2. **å¼·åŒ–å­¸ç¿’ï¼šåºåˆ—æ±ºç­–å„ªåŒ–**
        - State: ç•¶å‰éƒ¨åˆ†æ’ç­ç‹€æ…‹
        - Action: é¸æ“‡ä¸‹ä¸€å€‹é†«å¸«-æ—¥æœŸé…å°
        - Reward: åŸºæ–¼è©•åˆ†å‡½æ•¸çš„å³æ™‚å›é¥‹
        
        ### 3. **æ·±åº¦å­¸ç¿’ï¼šç«¯åˆ°ç«¯æ’ç­**
        ```python
        # ä½¿ç”¨Transformeræ¨¡å‹
        import torch.nn as nn
        
        class ScheduleTransformer(nn.Module):
            def __init__(self):
                self.encoder = nn.TransformerEncoder(...)
                self.decoder = nn.Linear(...)
        ```
        
        ### 4. **ç‰¹å¾µå·¥ç¨‹å»ºè­°**
        - **æ™‚åºç‰¹å¾µ**ï¼šæ˜ŸæœŸå¹¾ã€æœˆä»½ã€æ˜¯å¦æœˆåˆ/æœˆæœ«
        - **æ­·å²ç‰¹å¾µ**ï¼šé†«å¸«éå»çš„æ’ç­æ¨¡å¼
        - **äº¤äº’ç‰¹å¾µ**ï¼šé†«å¸«é–“çš„ç›¸å®¹æ€§
        - **ç´„æŸç·¨ç¢¼**ï¼šå°‡ç¡¬ç´„æŸè½‰ç‚ºç‰¹å¾µå‘é‡
        
        ### 5. **è©•ä¼°æŒ‡æ¨™**
        - **æº–ç¢ºç‡**ï¼šé æ¸¬åˆ†æ•¸èˆ‡å¯¦éš›åˆ†æ•¸çš„MAE
        - **å¯è¡Œæ€§**ï¼šç”Ÿæˆè§£çš„é•è¦ç‡
        - **å¤šæ¨£æ€§**ï¼šè§£çš„ç‰¹å¾µç©ºé–“è¦†è“‹åº¦
        - **æ•ˆç‡**ï¼šé”åˆ°ç›®æ¨™å“è³ªçš„è¿­ä»£æ¬¡æ•¸
        """)
    
    # è³‡æ–™å“è³ªæª¢æŸ¥
    st.subheader("âœ… è³‡æ–™å“è³ªæª¢æŸ¥")
    
    if st.session_state.last_scheduler and st.session_state.last_scheduler.solution_pool:
        pool_metrics = st.session_state.last_scheduler.solution_pool.get_diversity_metrics()
        grade_dist = pool_metrics.get('grade_distribution', {})
        
        quality_checks = {
            "è§£æ± å¤§å°å……è¶³ï¼ˆ>100ï¼‰": pool_metrics.get('pool_size', 0) > 100,
            "ç­‰ç´šåˆ†å¸ƒå¹³è¡¡": len(grade_dist) >= 3 if grade_dist else False,
            "ç‰¹å¾µå¤šæ¨£æ€§è‰¯å¥½ï¼ˆ>0.1ï¼‰": pool_metrics.get('feature_diversity', 0) > 0.1,
            "åŒ…å«å„ªè³ªè§£ï¼ˆS/Aç´šï¼‰": any(g in ['S', 'A'] for g in grade_dist.keys()) if grade_dist else False,
            "åŒ…å«å¤±æ•—æ¡ˆä¾‹ï¼ˆD/Fç´šï¼‰": any(g in ['D', 'F'] for g in grade_dist.keys()) if grade_dist else False
        }
        
        for check, passed in quality_checks.items():
            if passed:
                st.success(f"âœ… {check}")
            else:
                st.warning(f"âš ï¸ {check}")
        
        overall_quality = sum(quality_checks.values()) / len(quality_checks)
        st.progress(overall_quality)
        st.write(f"æ•´é«”è³‡æ–™å“è³ªï¼š{overall_quality*100:.0f}%")

def generate_analysis_report(solution_pool):
    """ç”Ÿæˆåˆ†æå ±å‘Š"""
    pool_metrics = solution_pool.get_diversity_metrics()
    grade_dist = pool_metrics.get('grade_distribution', {})
    top_solutions = solution_pool.get_top_solutions(5)
    
    report = f"""
# é†«å¸«æ’ç­MLè¨“ç·´è³‡æ–™åˆ†æå ±å‘Š
ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## è§£æ± çµ±è¨ˆ
- ç¸½è§£æ•¸é‡ï¼š{pool_metrics.get('pool_size', 0)}
- å”¯ä¸€è§£æ•¸é‡ï¼š{pool_metrics.get('unique_schedules', 0)}
- å¹³å‡åˆ†æ•¸ï¼š{pool_metrics.get('avg_score', 0):.2f}
- åˆ†æ•¸æ¨™æº–å·®ï¼š{pool_metrics.get('score_std', 0):.2f}
- ç‰¹å¾µå¤šæ¨£æ€§ï¼š{pool_metrics.get('feature_diversity', 0):.4f}

## ç­‰ç´šåˆ†å¸ƒ
"""
    
    for grade, count in grade_dist.items():
        percentage = (count / pool_metrics['pool_size']) * 100
        report += f"- {grade}ç´šï¼š{count}å€‹ ({percentage:.1f}%)\n"
    
    report += """
## æœ€ä½³è§£ç‰¹å¾µ
"""
    
    if top_solutions:
        best = top_solutions[0]
        report += f"""
- åˆ†æ•¸ï¼š{best.score:.1f}
- å¡«å……ç‡ï¼š{best.features.fill_rate*100:.1f}%
- ç¡¬é•è¦ï¼š{best.features.hard_violations}
- è»Ÿé•è¦ï¼š{best.features.soft_violations}
- åå¥½æ»¿è¶³ç‡ï¼š{best.features.preference_rate*100:.1f}%
- å…¬å¹³æ€§ï¼ˆGiniä¿‚æ•¸ï¼‰ï¼š{best.features.gini_coefficient:.3f}

## å»ºè­°
æ ¹æ“šè§£æ± åˆ†æï¼Œå»ºè­°ï¼š
1. é‡é»å„ªåŒ–{'å¡«å……ç‡' if pool_metrics['avg_score'] < -500 else 'å…¬å¹³æ€§'}
2. è€ƒæ…®{'æ”¾å¯¬ç´„æŸ' if grade_dist.get('F', 0) > pool_metrics['pool_size']*0.3 else 'ç¶­æŒç•¶å‰ç´„æŸ'}
3. {'å¢åŠ é†«å¸«é…é¡' if top_solutions[0].features.fill_rate < 0.9 else 'ç•¶å‰é…é¡åˆç†'}
"""
    
    return report